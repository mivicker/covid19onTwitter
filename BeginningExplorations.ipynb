{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('twitter.db')\n",
    "df = pd.read_sql(\"SELECT * FROM covid19tweets\", conn)\n",
    "usa = pd.read_sql(\"SELECT * FROM covid19tweets WHERE instr(user_loc_display,'United States')>0\",conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up some of the dtypes\n",
    "df = df.astype({'text': str, 'user_lat': float, 'user_lon': float})\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump all text into a long string\n",
    "text_blob = ' '.join(df['text'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams, trigrams, word_tokenize\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures, TrigramCollocationFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text_blob)\n",
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "nd selli… RT @ ClaireRChen : How did Putin deal with mask price surge ? It 's s\n",
      "ancy Upd… RT @ ClaireRChen : How did Putin deal with mask price surge ? It 's s\n",
      "rned pra… RT @ ClaireRChen : How did Putin deal with mask price surge ? It 's s\n",
      "nds way too familiar ! Are Trump and Putin keeping crucial supplies for th… RT \n",
      "nds way too familiar ! Are Trump and Putin keeping crucial supplies for th… Can\n"
     ]
    }
   ],
   "source": [
    "text.concordance('Putin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = BigramAssocMeasures()\n",
    "trigram_measures = TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams\n",
      "[('Agha', 'Khan'), ('Gargling', 'salt'), ('salt', 'water'), ('Some', 'fast'), ('intensive', 'unit…'), ('write', 'inaccurately'), ('DAY', 'Worst'), ('ONE', 'DAY'), ('45-minute', 'turnaround'), ('8,000', 'extra'), ('CONTAIN', 'VIRUS'), ('CPAP', 'oxygen'), ('nearly', '120…'), ('oxygen', 'tent'), ('red', 'tap'), ('regulatory', 'red'), ('troops', 'supporting'), ('unfounded', 'rumors'), ('Washington', 'Post'), ('DEAD', 'IN'), ('earned', 'pra…'), ('fast', 'facts'), ('informal', 'settlements'), ('NationalGuard', 'troops'), ('USNavyCNO', 'discusses'), ('Very', 'powerful'), ('gather', 'physically'), ('assistance', 'of…'), ('stay', 'apart'), ('appeal', 'again'), ('hard-hit', 'states'), ('chart', 'shows'), ('faith', 'leaders'), ('IN', 'ONE'), ('EU', 'Member'), ('provide', '8,000'), ('BATTLE', 'TO'), ('IS', 'LOST'), ('TO', 'CONTAIN'), ('VIRUS', 'IS'), ('hear', 'unfounded'), ('maximize', 'efforts'), ('past', '24'), ('Video', 'Update'), ('beds', 'across'), ('England', 'agrees'), ('agrees', 'deal'), ('benefits', 'under'), ('UN', 'Secretary-General'), ('Corona', 'Virus')]\n",
      "Trigrams\n",
      "[('Gargling', 'salt', 'water'), ('Some', 'fast', 'facts'), ('CPAP', 'oxygen', 'tent'), ('ONE', 'DAY', 'Worst'), ('regulatory', 'red', 'tap'), ('DEAD', 'IN', 'ONE'), ('IN', 'ONE', 'DAY'), ('NationalGuard', 'troops', 'supporting'), ('They', 'write', 'inaccurately'), ('BATTLE', 'TO', 'CONTAIN'), ('CONTAIN', 'VIRUS', 'IS'), ('TO', 'CONTAIN', 'VIRUS'), ('VIRUS', 'IS', 'LOST'), ('hear', 'unfounded', 'rumors'), ('provide', '8,000', 'extra'), ('Two', 'key', 'words'), ('Very', 'powerful', 'message'), ('past', '24', 'hours'), ('beds', 'across', 'England'), ('EU', 'Member', 'State'), ('another', 'EU', 'Member'), ('never', 'devastating', 'enough'), ('England', 'agrees', 'deal'), ('NHS', 'England', 'agrees'), ('chart', 'shows', 'why'), ('Agha', 'Khan', 'Hospital'), ('benefits', 'under', 'any'), ('cut', 'through', 'regulatory'), ('through', 'regulatory', 'red'), ('must', 'stay', 'apart'), ('getting', 'benefits', 'under'), ('793', 'DEAD', 'IN'), ('Paolo', 'Miranda', 'inside'), ('citizens', 'prepare/cope', 'w/'), ('NOT', 'prevent', 'infection'), ('8,000', 'extra', 'hospital'), ('any', 'government', 'scheme'), ('1500', 'through', 'CashApp'), ('45-minute', 'turnaround', 'approved'), ('extra', 'hospital', 'beds'), ('every', 'single', 'hou…'), ('other', 'hard-hit', 'states'), ('devastating', 'enough', 'Today'), ('salt', 'water', 'will'), ('hospital', 'beds', 'across'), ('vaccine', 'yet', '2'), ('water', 'will', 'NOT'), ('provided', 'an', 'assistance'), ('not', 'gather', 'physically'), ('More', 'than', '50')]\n"
     ]
    }
   ],
   "source": [
    "# took most of this section from nlp for hackers\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(tokens)\n",
    "# only bigrams that appear 5+ times\n",
    "finder.apply_freq_filter(5)\n",
    "# return the 50 bigrams with the highest PMI (Pointwise Mutual Information)\n",
    "#PMI is log(p(x, y)/(p(x)p(y)))\n",
    "print(\"Bigrams\")\n",
    "print(finder.nbest(bigram_measures.pmi, 50))\n",
    "# Compute length-3 collocations\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(tokens)\n",
    "# only trigrams that appear 5+ times\n",
    "finder.apply_freq_filter(5)\n",
    "# return the 50 trigrams with the highest PMI\n",
    "print(\"Trigrams\")\n",
    "print(finder.nbest(trigram_measures.pmi, 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_tweets = df['text'].str.lower()\n",
    "ngram_mask = lower_tweets.str.contains('not gather physically')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_lat</th>\n",
       "      <th>user_lon</th>\n",
       "      <th>user_loc_display</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>222</td>\n",
       "      <td>2020-03-21 20:02:06</td>\n",
       "      <td>RT @JustinWelby: As UK faith leaders, we appea...</td>\n",
       "      <td>None</td>\n",
       "      <td>Launceston Cornwall</td>\n",
       "      <td>50.636506</td>\n",
       "      <td>-4.360443</td>\n",
       "      <td>Launceston, Cornwall, South West England, Engl...</td>\n",
       "      <td>1241455062846787584</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>222</td>\n",
       "      <td>2020-03-21 20:02:03</td>\n",
       "      <td>RT @JustinWelby: As UK faith leaders, we appea...</td>\n",
       "      <td>None</td>\n",
       "      <td>Enugu, Nigeria</td>\n",
       "      <td>6.553609</td>\n",
       "      <td>7.414306</td>\n",
       "      <td>Enugu, Nigeria</td>\n",
       "      <td>1241455049424896001</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>286</td>\n",
       "      <td>2020-03-21 20:40:05</td>\n",
       "      <td>RT @JustinWelby: As UK faith leaders, we appea...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1241464620537315330</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>328</td>\n",
       "      <td>2020-03-21 21:00:33</td>\n",
       "      <td>RT @JustinWelby: As UK faith leaders, we appea...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1241469771276746753</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>338</td>\n",
       "      <td>2020-03-21 21:07:27</td>\n",
       "      <td>RT @JustinWelby: As UK faith leaders, we appea...</td>\n",
       "      <td>None</td>\n",
       "      <td>Witney</td>\n",
       "      <td>51.785937</td>\n",
       "      <td>-1.485059</td>\n",
       "      <td>Witney, Oxfordshire, South East, England, OX28...</td>\n",
       "      <td>1241471507311853568</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>338</td>\n",
       "      <td>2020-03-21 21:07:25</td>\n",
       "      <td>RT @JustinWelby: As UK faith leaders, we appea...</td>\n",
       "      <td>None</td>\n",
       "      <td>Aldgate High Street</td>\n",
       "      <td>51.514017</td>\n",
       "      <td>-0.075316</td>\n",
       "      <td>Aldgate High Street, City of London, Greater L...</td>\n",
       "      <td>1241471497723621378</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>338</td>\n",
       "      <td>2020-03-21 21:07:11</td>\n",
       "      <td>RT @JustinWelby: As UK faith leaders, we appea...</td>\n",
       "      <td>None</td>\n",
       "      <td>Little Kingshill</td>\n",
       "      <td>51.684956</td>\n",
       "      <td>-0.704058</td>\n",
       "      <td>Little Kingshill, Buckinghamshire, South East,...</td>\n",
       "      <td>1241471440576303106</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     retweet_count          created_at  \\\n",
       "57             222 2020-03-21 20:02:06   \n",
       "79             222 2020-03-21 20:02:03   \n",
       "595            286 2020-03-21 20:40:05   \n",
       "887            328 2020-03-21 21:00:33   \n",
       "911            338 2020-03-21 21:07:27   \n",
       "922            338 2020-03-21 21:07:25   \n",
       "997            338 2020-03-21 21:07:11   \n",
       "\n",
       "                                                  text coordinates  \\\n",
       "57   RT @JustinWelby: As UK faith leaders, we appea...        None   \n",
       "79   RT @JustinWelby: As UK faith leaders, we appea...        None   \n",
       "595  RT @JustinWelby: As UK faith leaders, we appea...        None   \n",
       "887  RT @JustinWelby: As UK faith leaders, we appea...        None   \n",
       "911  RT @JustinWelby: As UK faith leaders, we appea...        None   \n",
       "922  RT @JustinWelby: As UK faith leaders, we appea...        None   \n",
       "997  RT @JustinWelby: As UK faith leaders, we appea...        None   \n",
       "\n",
       "                user_loc   user_lat  user_lon  \\\n",
       "57   Launceston Cornwall  50.636506 -4.360443   \n",
       "79        Enugu, Nigeria   6.553609  7.414306   \n",
       "595                             NaN       NaN   \n",
       "887                             NaN       NaN   \n",
       "911               Witney  51.785937 -1.485059   \n",
       "922  Aldgate High Street  51.514017 -0.075316   \n",
       "997    Little Kingshill   51.684956 -0.704058   \n",
       "\n",
       "                                      user_loc_display                   id  \\\n",
       "57   Launceston, Cornwall, South West England, Engl...  1241455062846787584   \n",
       "79                                      Enugu, Nigeria  1241455049424896001   \n",
       "595                                               None  1241464620537315330   \n",
       "887                                               None  1241469771276746753   \n",
       "911  Witney, Oxfordshire, South East, England, OX28...  1241471507311853568   \n",
       "922  Aldgate High Street, City of London, Greater L...  1241471497723621378   \n",
       "997  Little Kingshill, Buckinghamshire, South East,...  1241471440576303106   \n",
       "\n",
       "                  source  \n",
       "57    Twitter for iPhone  \n",
       "79   Twitter for Android  \n",
       "595   Twitter for iPhone  \n",
       "887  Twitter for Android  \n",
       "911   Twitter for iPhone  \n",
       "922      Twitter Web App  \n",
       "997      Twitter Web App  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ngram_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates to avoid RT messing up the ngram counts\n",
    "df_no_RT = df.drop_duplicates('text')\n",
    "#rerun the tokenization\n",
    "text_blob_no_RT = ' '.join(df_no_RT['text'].to_list())\n",
    "tokens_no_RT = word_tokenize(text_blob_no_RT)\n",
    "text_no_RT = nltk.Text(tokens_no_RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "[('South', 'Korea'), ('past', '24'), ('death', 'toll'), ('24', 'hours'), ('New', 'York'), ('social', 'distancing'), ('how', 'citizens'), ('health', 'care'), ('understand', 'how'), ('your', 'hands'), ('&', 'amp'), ('amp', ';'), ('deal', 'with'), ('Thank', 'you'), ('’', 'm'), ('’', 're'), ('’', 't'), ('’', 've'), ('’', 's'), ('confirmed', 'cases'), ('at', 'home'), ('don', '’'), ('has', 'been'), ('If', 'you'), ('has', 'confirmed'), ('a', 'lot'), ('It', \"'s\"), ('if', 'you'), ('Here', 'are'), ('will', 'be'), ('have', 'been'), ('new', 'cases'), ('test', 'that'), ('number', 'of'), ('``', 'We'), ('This', 'is'), ('there', 'are'), ('can', 'be'), ('part', 'of'), ('We', 'have'), ('during', 'this'), ('positive', 'for'), ('COVID19', 'case'), ('Due', 'to'), ('due', 'to'), ('to', 'combat'), ('and', 'other'), ('COVID19…', 'https'), ('that', 'can'), ('!', '!')]\n",
      "Trigrams\n",
      "[('past', '24', 'hours'), ('don', '’', 't'), ('&', 'amp', ';'), ('the', 'past', '24'), ('I', '’', 'm'), ('you', '’', 're'), ('If', 'you', 'have'), ('coronavirus', 'test', 'that'), ('new', 'cases', 'of'), ('.', 'If', 'you'), ('in', 'the', 'past'), ('the', 'number', 'of'), ('the', 'spread', 'of'), ('#', 'COVID19', 'case'), ('#', 'COVID19…', 'https'), ('COVID19…', 'https', ':'), ('CO…', 'RT', '@'), ('RT', '@', 'DrEricDing'), ('RT', '@', 'evankirstel'), ('RT', '@', 'DrDenaGrayson'), ('RT', '@', 'SkyNews'), ('Due', 'to', '#'), ('#', 'CO…', 'RT'), ('a…', 'RT', '@'), ('#', 'COVID19', 'pandemic'), (':', 'Due', 'to'), ('the…', 'RT', '@'), ('COVID19', 'pandemic', ','), ('the', 'total', 'to'), ('coronavirus', '#', 'covid19'), ('w…', 'RT', '@'), ('@', 'irmaraste', '@'), ('@', 'DrDenaGrayson', ':'), ('@', 'DrEricDing', ':'), ('@', 'evankirstel', ':'), ('…', 'RT', '@'), ('cases', 'of', '#'), ('t…', 'RT', '@'), ('#', 'Covid_19', '#'), ('@', 'SkyNews', ':'), ('response', 'to', '#'), ('…', 'https', ':'), ('spread', 'of', '#'), ('during', 'the', '#'), ('covid19', 'https', ':'), ('new', '#', 'coronavirus'), ('#', 'covid19', 'https'), ('#', 'coronavirus', 'cases'), ('#', 'COVID19', ')'), ('#', 'CoronaVirus', '#')]\n"
     ]
    }
   ],
   "source": [
    "finder = BigramCollocationFinder.from_words(tokens_no_RT)\n",
    "# only bigrams that appear 5+ times\n",
    "finder.apply_freq_filter(5)\n",
    "# return the 50 bigrams with the highest PMI (Pointwise Mutual Information)\n",
    "#PMI is log(p(x, y)/(p(x)p(y)))\n",
    "print(\"Bigrams:\")\n",
    "print(finder.nbest(bigram_measures.pmi, 50))\n",
    "# Compute length-3 collocations\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(tokens_no_RT)\n",
    "# only trigrams that appear 5+ times\n",
    "finder.apply_freq_filter(5)\n",
    "# return the 50 trigrams with the highest PMI\n",
    "print(\"Trigrams\")\n",
    "print(finder.nbest(trigram_measures.pmi, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 from 2020-03-21 20:02:00 to 2020-03-21 20:12:00\n",
      "0 from 2020-03-21 20:12:00 to 2020-03-21 20:22:00\n",
      "2 from 2020-03-21 20:22:00 to 2020-03-21 20:32:00\n",
      "2 from 2020-03-21 20:32:00 to 2020-03-21 20:42:00\n",
      "0 from 2020-03-21 20:42:00 to 2020-03-21 20:52:00\n",
      "0 from 2020-03-21 20:52:00 to 2020-03-21 21:02:00\n",
      "0 from 2020-03-21 21:02:00 to 2020-03-21 21:12:00\n",
      "0 from 2020-03-21 21:12:00 to 2020-03-21 21:22:00\n"
     ]
    }
   ],
   "source": [
    "def bin_messages_containing(df, string, freq='5min'):\n",
    "    \"\"\"\n",
    "    Selects the tweets that contain a given string, and then counts them in a given time step.\n",
    "    \"\"\"\n",
    "    first_time = df['created_at'].min()\n",
    "    last_time = df['created_at'].max()\n",
    "    date_range = pd.date_range(first_time, last_time, freq = freq)\n",
    "    \n",
    "    lower_tweets = df['text'].str.lower()\n",
    "    contains_mask = lower_tweets.str.contains(string)\n",
    "    \n",
    "    for index, _ in enumerate(date_range[:-1]):\n",
    "        block_start = date_range[index]\n",
    "        block_end = date_range[index + 1]\n",
    "        filt = (df['created_at'] > block_start) & (df['created_at'] < block_end) & contains_mask\n",
    "        print(str(len(df[filt])) + f' from {block_start} to {block_end}')\n",
    "\n",
    "string = \"putin\"\n",
    "bin_messages_containing(df, string, freq='10min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
